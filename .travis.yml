language: scala
sudo: required
dist: xenial
cache:
  directories:
    - $HOME/.ivy2
    - $HOME/spark
    - $HOME/.sbt/launchers
jdk:
  - openjdk8
scala:
   - 2.11.12
sudo: false

addons:
  apt:
    packages:
      - axel

before_install:
  - export PATH=$HOME/.local/bin:$PATH
install:
  # Download spark 2.3.2
  - "[ -f spark ] || mkdir spark && cd spark && axel https://archive.apache.org/dist/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz && cd .."
  - "tar -xf ./spark/spark-2.3.2-bin-hadoop2.7.tgz"
  - "export SPARK_HOME=`pwd`/spark-2.3.2-bin-hadoop2.7"
  - echo "spark.yarn.jars=$SPARK_HOME/jars/*.jar" > $SPARK_HOME/conf/spark-defaults.conf


stages:
- name: test
- name: release
  if: branch = master

jobs:
  include:
    - &test
      stage: test
      name: "Check code"
      script: sbt ++$TRAVIS_SCALA_VERSION test
    - &scaladoc
          stage: release
          name: "Generate Scaladoc"
          script:
            - sbt ++$TRAVIS_SCALA_VERSION doc
            - cp -r ./target/scala-2.11/api/ docs/

